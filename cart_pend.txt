/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
{"ALGO": "ppo_sam"}
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cuda
Log path: ./runs/sam_ppo_Pendulum_checkpoints/ppo_sam/Pendulum-v1_4
saved checkpoint 0010000
Eval num_timesteps=10000, episode_reward=-1290.99 +/- 308.64
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0020000
Eval num_timesteps=20000, episode_reward=-1205.42 +/- 304.29
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0030000
Eval num_timesteps=30000, episode_reward=-1256.07 +/- 271.09
Episode length: 200.00 +/- 0.00
saved checkpoint 0040000
Eval num_timesteps=40000, episode_reward=-1193.62 +/- 269.39
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0050000
Eval num_timesteps=50000, episode_reward=-1110.82 +/- 259.07
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0060000
Eval num_timesteps=60000, episode_reward=-1170.28 +/- 286.31
Episode length: 200.00 +/- 0.00
saved checkpoint 0070000
Eval num_timesteps=70000, episode_reward=-1167.77 +/- 262.41
Episode length: 200.00 +/- 0.00
saved checkpoint 0080000
Eval num_timesteps=80000, episode_reward=-1140.38 +/- 240.06
Episode length: 200.00 +/- 0.00
saved checkpoint 0090000
Eval num_timesteps=90000, episode_reward=-1133.98 +/- 255.35
Episode length: 200.00 +/- 0.00
saved checkpoint 0100000
Eval num_timesteps=100000, episode_reward=-1093.50 +/- 200.37
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0110000
Eval num_timesteps=110000, episode_reward=-1135.56 +/- 199.60
Episode length: 200.00 +/- 0.00
saved checkpoint 0120000
Eval num_timesteps=120000, episode_reward=-1069.11 +/- 176.25
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0130000
Eval num_timesteps=130000, episode_reward=-1093.91 +/- 214.25
Episode length: 200.00 +/- 0.00
saved checkpoint 0140000
Eval num_timesteps=140000, episode_reward=-1010.44 +/- 155.01
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0150000
Eval num_timesteps=150000, episode_reward=-1056.75 +/- 193.75
Episode length: 200.00 +/- 0.00
saved checkpoint 0160000
Eval num_timesteps=160000, episode_reward=-1060.72 +/- 192.25
Episode length: 200.00 +/- 0.00
saved checkpoint 0170000
Eval num_timesteps=170000, episode_reward=-973.66 +/- 193.77
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0180000
Eval num_timesteps=180000, episode_reward=-985.01 +/- 184.42
Episode length: 200.00 +/- 0.00
saved checkpoint 0190000
Eval num_timesteps=190000, episode_reward=-987.73 +/- 170.63
Episode length: 200.00 +/- 0.00
saved checkpoint 0200000
Eval num_timesteps=200000, episode_reward=-853.86 +/- 134.08
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0210000
Eval num_timesteps=210000, episode_reward=-929.18 +/- 151.61
Episode length: 200.00 +/- 0.00
saved checkpoint 0220000
Eval num_timesteps=220000, episode_reward=-895.10 +/- 180.53
Episode length: 200.00 +/- 0.00
saved checkpoint 0230000
Eval num_timesteps=230000, episode_reward=-726.36 +/- 157.25
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0240000
Eval num_timesteps=240000, episode_reward=-751.05 +/- 149.24
Episode length: 200.00 +/- 0.00
saved checkpoint 0250000
Eval num_timesteps=250000, episode_reward=-742.45 +/- 129.24
Episode length: 200.00 +/- 0.00
saved checkpoint 0260000
Eval num_timesteps=260000, episode_reward=-745.65 +/- 148.07
Episode length: 200.00 +/- 0.00
saved checkpoint 0270000
Eval num_timesteps=270000, episode_reward=-565.26 +/- 155.64
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0280000
Eval num_timesteps=280000, episode_reward=-597.48 +/- 156.00
Episode length: 200.00 +/- 0.00
saved checkpoint 0290000
Eval num_timesteps=290000, episode_reward=-567.28 +/- 186.30
Episode length: 200.00 +/- 0.00
saved checkpoint 0300000
Eval num_timesteps=300000, episode_reward=-416.35 +/- 191.99
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0310000
Eval num_timesteps=310000, episode_reward=-385.93 +/- 172.10
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0320000
Eval num_timesteps=320000, episode_reward=-462.14 +/- 213.11
Episode length: 200.00 +/- 0.00
saved checkpoint 0330000
Eval num_timesteps=330000, episode_reward=-306.37 +/- 142.61
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0340000
Eval num_timesteps=340000, episode_reward=-277.35 +/- 174.02
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0350000
Eval num_timesteps=350000, episode_reward=-327.59 +/- 179.81
Episode length: 200.00 +/- 0.00
saved checkpoint 0360000
Eval num_timesteps=360000, episode_reward=-302.72 +/- 172.49
Episode length: 200.00 +/- 0.00
saved checkpoint 0370000
Eval num_timesteps=370000, episode_reward=-214.55 +/- 136.22
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0380000
Eval num_timesteps=380000, episode_reward=-248.84 +/- 137.81
Episode length: 200.00 +/- 0.00
saved checkpoint 0390000
Eval num_timesteps=390000, episode_reward=-243.30 +/- 130.69
Episode length: 200.00 +/- 0.00
saved checkpoint 0400000
Eval num_timesteps=400000, episode_reward=-216.81 +/- 155.03
Episode length: 200.00 +/- 0.00
saved checkpoint 0410000
Eval num_timesteps=410000, episode_reward=-217.53 +/- 136.97
Episode length: 200.00 +/- 0.00
saved checkpoint 0420000
Eval num_timesteps=420000, episode_reward=-227.72 +/- 115.38
Episode length: 200.00 +/- 0.00
saved checkpoint 0430000
Eval num_timesteps=430000, episode_reward=-230.98 +/- 131.75
Episode length: 200.00 +/- 0.00
saved checkpoint 0440000
Eval num_timesteps=440000, episode_reward=-258.94 +/- 139.72
Episode length: 200.00 +/- 0.00
saved checkpoint 0450000
Eval num_timesteps=450000, episode_reward=-216.34 +/- 130.71
Episode length: 200.00 +/- 0.00
saved checkpoint 0460000
Eval num_timesteps=460000, episode_reward=-221.50 +/- 136.75
Episode length: 200.00 +/- 0.00
saved checkpoint 0470000
Eval num_timesteps=470000, episode_reward=-211.47 +/- 128.30
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0480000
Eval num_timesteps=480000, episode_reward=-183.74 +/- 127.63
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0490000
Eval num_timesteps=490000, episode_reward=-193.57 +/- 130.29
Episode length: 200.00 +/- 0.00
saved checkpoint 0500000
Eval num_timesteps=500000, episode_reward=-197.54 +/- 125.20
Episode length: 200.00 +/- 0.00
saved checkpoint 0510000
Eval num_timesteps=510000, episode_reward=-181.93 +/- 124.30
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0520000
Eval num_timesteps=520000, episode_reward=-208.08 +/- 138.92
Episode length: 200.00 +/- 0.00
saved checkpoint 0530000
Eval num_timesteps=530000, episode_reward=-174.91 +/- 105.52
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0540000
Eval num_timesteps=540000, episode_reward=-184.90 +/- 126.09
Episode length: 200.00 +/- 0.00
saved checkpoint 0550000
Eval num_timesteps=550000, episode_reward=-200.61 +/- 116.56
Episode length: 200.00 +/- 0.00
saved checkpoint 0560000
Eval num_timesteps=560000, episode_reward=-191.11 +/- 111.92
Episode length: 200.00 +/- 0.00
saved checkpoint 0570000
Eval num_timesteps=570000, episode_reward=-187.81 +/- 115.26
Episode length: 200.00 +/- 0.00
saved checkpoint 0580000
Eval num_timesteps=580000, episode_reward=-194.57 +/- 99.90
Episode length: 200.00 +/- 0.00
saved checkpoint 0590000
Eval num_timesteps=590000, episode_reward=-174.70 +/- 87.68
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0600000
Eval num_timesteps=600000, episode_reward=-175.79 +/- 124.40
Episode length: 200.00 +/- 0.00
saved checkpoint 0610000
Eval num_timesteps=610000, episode_reward=-196.81 +/- 109.61
Episode length: 200.00 +/- 0.00
saved checkpoint 0620000
Eval num_timesteps=620000, episode_reward=-160.46 +/- 101.57
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0630000
Eval num_timesteps=630000, episode_reward=-199.89 +/- 109.57
Episode length: 200.00 +/- 0.00
saved checkpoint 0640000
Eval num_timesteps=640000, episode_reward=-169.65 +/- 106.80
Episode length: 200.00 +/- 0.00
saved checkpoint 0650000
Eval num_timesteps=650000, episode_reward=-179.72 +/- 116.14
Episode length: 200.00 +/- 0.00
saved checkpoint 0660000
Eval num_timesteps=660000, episode_reward=-170.07 +/- 109.77
Episode length: 200.00 +/- 0.00
saved checkpoint 0670000
Eval num_timesteps=670000, episode_reward=-187.24 +/- 109.83
Episode length: 200.00 +/- 0.00
saved checkpoint 0680000
Eval num_timesteps=680000, episode_reward=-167.00 +/- 104.70
Episode length: 200.00 +/- 0.00
saved checkpoint 0690000
Eval num_timesteps=690000, episode_reward=-156.57 +/- 105.66
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0700000
Eval num_timesteps=700000, episode_reward=-184.51 +/- 116.99
Episode length: 200.00 +/- 0.00
saved checkpoint 0710000
Eval num_timesteps=710000, episode_reward=-172.11 +/- 86.97
Episode length: 200.00 +/- 0.00
saved checkpoint 0720000
Eval num_timesteps=720000, episode_reward=-158.97 +/- 107.13
Episode length: 200.00 +/- 0.00
saved checkpoint 0730000
Eval num_timesteps=730000, episode_reward=-159.00 +/- 94.93
Episode length: 200.00 +/- 0.00
saved checkpoint 0740000
Eval num_timesteps=740000, episode_reward=-158.17 +/- 104.61
Episode length: 200.00 +/- 0.00
saved checkpoint 0750000
Eval num_timesteps=750000, episode_reward=-151.57 +/- 87.09
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0760000
Eval num_timesteps=760000, episode_reward=-149.01 +/- 98.83
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0770000
Eval num_timesteps=770000, episode_reward=-193.06 +/- 99.35
Episode length: 200.00 +/- 0.00
saved checkpoint 0780000
Eval num_timesteps=780000, episode_reward=-192.29 +/- 91.48
Episode length: 200.00 +/- 0.00
saved checkpoint 0790000
Eval num_timesteps=790000, episode_reward=-141.97 +/- 86.23
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0800000
Eval num_timesteps=800000, episode_reward=-142.54 +/- 95.56
Episode length: 200.00 +/- 0.00
saved checkpoint 0810000
Eval num_timesteps=810000, episode_reward=-165.95 +/- 103.47
Episode length: 200.00 +/- 0.00
saved checkpoint 0820000
Eval num_timesteps=820000, episode_reward=-154.69 +/- 89.41
Episode length: 200.00 +/- 0.00
saved checkpoint 0830000
Eval num_timesteps=830000, episode_reward=-175.06 +/- 101.39
Episode length: 200.00 +/- 0.00
saved checkpoint 0840000
Eval num_timesteps=840000, episode_reward=-154.34 +/- 88.86
Episode length: 200.00 +/- 0.00
saved checkpoint 0850000
Eval num_timesteps=850000, episode_reward=-167.73 +/- 101.69
Episode length: 200.00 +/- 0.00
saved checkpoint 0860000
Eval num_timesteps=860000, episode_reward=-164.12 +/- 84.80
Episode length: 200.00 +/- 0.00
saved checkpoint 0870000
Eval num_timesteps=870000, episode_reward=-142.15 +/- 74.89
Episode length: 200.00 +/- 0.00
saved checkpoint 0880000
Eval num_timesteps=880000, episode_reward=-168.17 +/- 88.27
Episode length: 200.00 +/- 0.00
saved checkpoint 0890000
Eval num_timesteps=890000, episode_reward=-145.60 +/- 81.87
Episode length: 200.00 +/- 0.00
saved checkpoint 0900000
Eval num_timesteps=900000, episode_reward=-163.69 +/- 85.66
Episode length: 200.00 +/- 0.00
saved checkpoint 0910000
Eval num_timesteps=910000, episode_reward=-159.80 +/- 83.40
Episode length: 200.00 +/- 0.00
saved checkpoint 0920000
Eval num_timesteps=920000, episode_reward=-153.06 +/- 89.13
Episode length: 200.00 +/- 0.00
saved checkpoint 0930000
Eval num_timesteps=930000, episode_reward=-156.85 +/- 92.23
Episode length: 200.00 +/- 0.00
saved checkpoint 0940000
Eval num_timesteps=940000, episode_reward=-167.05 +/- 103.66
Episode length: 200.00 +/- 0.00
saved checkpoint 0950000
Eval num_timesteps=950000, episode_reward=-137.12 +/- 79.65
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 0960000
Eval num_timesteps=960000, episode_reward=-146.23 +/- 100.06
Episode length: 200.00 +/- 0.00
saved checkpoint 0970000
Eval num_timesteps=970000, episode_reward=-137.86 +/- 90.88
Episode length: 200.00 +/- 0.00
saved checkpoint 0980000
Eval num_timesteps=980000, episode_reward=-146.10 +/- 89.55
Episode length: 200.00 +/- 0.00
saved checkpoint 0990000
Eval num_timesteps=990000, episode_reward=-134.27 +/- 97.31
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 1000000
Eval num_timesteps=1000000, episode_reward=-147.28 +/- 87.24
Episode length: 200.00 +/- 0.00
saved checkpoint 1010000
Eval num_timesteps=1010000, episode_reward=-148.16 +/- 101.49
Episode length: 200.00 +/- 0.00
saved checkpoint 1020000
Eval num_timesteps=1020000, episode_reward=-157.46 +/- 97.55
Episode length: 200.00 +/- 0.00
saved checkpoint 1030000
Eval num_timesteps=1030000, episode_reward=-149.44 +/- 69.90
Episode length: 200.00 +/- 0.00
saved checkpoint 1040000
Eval num_timesteps=1040000, episode_reward=-130.83 +/- 91.72
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 1050000
Eval num_timesteps=1050000, episode_reward=-157.02 +/- 78.77
Episode length: 200.00 +/- 0.00
saved checkpoint 1060000
Eval num_timesteps=1060000, episode_reward=-139.29 +/- 69.51
Episode length: 200.00 +/- 0.00
saved checkpoint 1070000
Eval num_timesteps=1070000, episode_reward=-165.42 +/- 93.62
Episode length: 200.00 +/- 0.00
saved checkpoint 1080000
Eval num_timesteps=1080000, episode_reward=-151.64 +/- 92.84
Episode length: 200.00 +/- 0.00
saved checkpoint 1090000
Eval num_timesteps=1090000, episode_reward=-167.99 +/- 99.29
Episode length: 200.00 +/- 0.00
saved checkpoint 1100000
Eval num_timesteps=1100000, episode_reward=-142.45 +/- 89.19
Episode length: 200.00 +/- 0.00
saved checkpoint 1110000
Eval num_timesteps=1110000, episode_reward=-165.27 +/- 95.19
Episode length: 200.00 +/- 0.00
saved checkpoint 1120000
Eval num_timesteps=1120000, episode_reward=-144.20 +/- 89.72
Episode length: 200.00 +/- 0.00
saved checkpoint 1130000
Eval num_timesteps=1130000, episode_reward=-155.25 +/- 94.33
Episode length: 200.00 +/- 0.00
saved checkpoint 1140000
Eval num_timesteps=1140000, episode_reward=-155.68 +/- 77.96
Episode length: 200.00 +/- 0.00
saved checkpoint 1150000
Eval num_timesteps=1150000, episode_reward=-154.64 +/- 98.55
Episode length: 200.00 +/- 0.00
saved checkpoint 1160000
Eval num_timesteps=1160000, episode_reward=-153.54 +/- 88.32
Episode length: 200.00 +/- 0.00
saved checkpoint 1170000
Eval num_timesteps=1170000, episode_reward=-145.00 +/- 85.97
Episode length: 200.00 +/- 0.00
saved checkpoint 1180000
Eval num_timesteps=1180000, episode_reward=-134.43 +/- 94.38
Episode length: 200.00 +/- 0.00
saved checkpoint 1190000
Eval num_timesteps=1190000, episode_reward=-149.68 +/- 98.48
Episode length: 200.00 +/- 0.00
saved checkpoint 1200000
Eval num_timesteps=1200000, episode_reward=-157.74 +/- 97.31
Episode length: 200.00 +/- 0.00
saved checkpoint 1210000
Eval num_timesteps=1210000, episode_reward=-145.70 +/- 78.40
Episode length: 200.00 +/- 0.00
saved checkpoint 1220000
Eval num_timesteps=1220000, episode_reward=-144.44 +/- 97.10
Episode length: 200.00 +/- 0.00
saved checkpoint 1230000
Eval num_timesteps=1230000, episode_reward=-138.38 +/- 81.33
Episode length: 200.00 +/- 0.00
saved checkpoint 1240000
Eval num_timesteps=1240000, episode_reward=-137.67 +/- 93.03
Episode length: 200.00 +/- 0.00
saved checkpoint 1250000
Eval num_timesteps=1250000, episode_reward=-146.25 +/- 80.60
Episode length: 200.00 +/- 0.00
saved checkpoint 1260000
Eval num_timesteps=1260000, episode_reward=-150.06 +/- 92.95
Episode length: 200.00 +/- 0.00
saved checkpoint 1270000
Eval num_timesteps=1270000, episode_reward=-152.77 +/- 86.46
Episode length: 200.00 +/- 0.00
saved checkpoint 1280000
Eval num_timesteps=1280000, episode_reward=-131.43 +/- 83.69
Episode length: 200.00 +/- 0.00
saved checkpoint 1290000
Eval num_timesteps=1290000, episode_reward=-144.42 +/- 93.06
Episode length: 200.00 +/- 0.00
saved checkpoint 1300000
Eval num_timesteps=1300000, episode_reward=-158.61 +/- 73.49
Episode length: 200.00 +/- 0.00
saved checkpoint 1310000
Eval num_timesteps=1310000, episode_reward=-153.91 +/- 94.30
Episode length: 200.00 +/- 0.00
saved checkpoint 1320000
Eval num_timesteps=1320000, episode_reward=-156.62 +/- 76.97
Episode length: 200.00 +/- 0.00
saved checkpoint 1330000
Eval num_timesteps=1330000, episode_reward=-123.93 +/- 79.98
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 1340000
Eval num_timesteps=1340000, episode_reward=-128.97 +/- 80.32
Episode length: 200.00 +/- 0.00
saved checkpoint 1350000
Eval num_timesteps=1350000, episode_reward=-138.80 +/- 81.21
Episode length: 200.00 +/- 0.00
saved checkpoint 1360000
Eval num_timesteps=1360000, episode_reward=-175.22 +/- 86.37
Episode length: 200.00 +/- 0.00
saved checkpoint 1370000
Eval num_timesteps=1370000, episode_reward=-137.65 +/- 85.47
Episode length: 200.00 +/- 0.00
saved checkpoint 1380000
Eval num_timesteps=1380000, episode_reward=-146.19 +/- 91.04
Episode length: 200.00 +/- 0.00
saved checkpoint 1390000
Eval num_timesteps=1390000, episode_reward=-139.41 +/- 76.15
Episode length: 200.00 +/- 0.00
saved checkpoint 1400000
Eval num_timesteps=1400000, episode_reward=-153.95 +/- 95.18
Episode length: 200.00 +/- 0.00
saved checkpoint 1410000
Eval num_timesteps=1410000, episode_reward=-150.07 +/- 90.76
Episode length: 200.00 +/- 0.00
saved checkpoint 1420000
Eval num_timesteps=1420000, episode_reward=-149.45 +/- 97.03
Episode length: 200.00 +/- 0.00
saved checkpoint 1430000
Eval num_timesteps=1430000, episode_reward=-157.29 +/- 72.07
Episode length: 200.00 +/- 0.00
saved checkpoint 1440000
Eval num_timesteps=1440000, episode_reward=-137.34 +/- 93.12
Episode length: 200.00 +/- 0.00
saved checkpoint 1450000
Eval num_timesteps=1450000, episode_reward=-145.03 +/- 90.57
Episode length: 200.00 +/- 0.00
saved checkpoint 1460000
Eval num_timesteps=1460000, episode_reward=-143.89 +/- 86.14
Episode length: 200.00 +/- 0.00
saved checkpoint 1470000
Eval num_timesteps=1470000, episode_reward=-151.96 +/- 82.47
Episode length: 200.00 +/- 0.00
saved checkpoint 1480000
Eval num_timesteps=1480000, episode_reward=-154.45 +/- 91.36
Episode length: 200.00 +/- 0.00
saved checkpoint 1490000
Eval num_timesteps=1490000, episode_reward=-150.39 +/- 75.26
Episode length: 200.00 +/- 0.00
saved checkpoint 1500000
Eval num_timesteps=1500000, episode_reward=-155.39 +/- 74.53
Episode length: 200.00 +/- 0.00
saved checkpoint 1510000
Eval num_timesteps=1510000, episode_reward=-175.01 +/- 92.76
Episode length: 200.00 +/- 0.00
saved checkpoint 1520000
Eval num_timesteps=1520000, episode_reward=-149.82 +/- 69.75
Episode length: 200.00 +/- 0.00
saved checkpoint 1530000
Eval num_timesteps=1530000, episode_reward=-157.67 +/- 88.88
Episode length: 200.00 +/- 0.00
saved checkpoint 1540000
Eval num_timesteps=1540000, episode_reward=-173.33 +/- 98.94
Episode length: 200.00 +/- 0.00
saved checkpoint 1550000
Eval num_timesteps=1550000, episode_reward=-148.57 +/- 89.10
Episode length: 200.00 +/- 0.00
saved checkpoint 1560000
Eval num_timesteps=1560000, episode_reward=-146.40 +/- 91.78
Episode length: 200.00 +/- 0.00
saved checkpoint 1570000
Eval num_timesteps=1570000, episode_reward=-155.02 +/- 77.75
Episode length: 200.00 +/- 0.00
saved checkpoint 1580000
Eval num_timesteps=1580000, episode_reward=-115.88 +/- 78.70
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 1590000
Eval num_timesteps=1590000, episode_reward=-136.20 +/- 57.38
Episode length: 200.00 +/- 0.00
saved checkpoint 1600000
Eval num_timesteps=1600000, episode_reward=-137.38 +/- 86.26
Episode length: 200.00 +/- 0.00
saved checkpoint 1610000
Eval num_timesteps=1610000, episode_reward=-119.24 +/- 82.42
Episode length: 200.00 +/- 0.00
saved checkpoint 1620000
Eval num_timesteps=1620000, episode_reward=-135.45 +/- 81.62
Episode length: 200.00 +/- 0.00
saved checkpoint 1630000
Eval num_timesteps=1630000, episode_reward=-147.55 +/- 98.85
Episode length: 200.00 +/- 0.00
saved checkpoint 1640000
Eval num_timesteps=1640000, episode_reward=-165.52 +/- 101.92
Episode length: 200.00 +/- 0.00
saved checkpoint 1650000
Eval num_timesteps=1650000, episode_reward=-146.44 +/- 76.75
Episode length: 200.00 +/- 0.00
saved checkpoint 1660000
Eval num_timesteps=1660000, episode_reward=-150.94 +/- 80.51
Episode length: 200.00 +/- 0.00
saved checkpoint 1670000
Eval num_timesteps=1670000, episode_reward=-139.41 +/- 64.88
Episode length: 200.00 +/- 0.00
saved checkpoint 1680000
Eval num_timesteps=1680000, episode_reward=-145.63 +/- 82.93
Episode length: 200.00 +/- 0.00
saved checkpoint 1690000
Eval num_timesteps=1690000, episode_reward=-141.00 +/- 70.98
Episode length: 200.00 +/- 0.00
saved checkpoint 1700000
Eval num_timesteps=1700000, episode_reward=-153.83 +/- 79.05
Episode length: 200.00 +/- 0.00
saved checkpoint 1710000
Eval num_timesteps=1710000, episode_reward=-143.05 +/- 92.40
Episode length: 200.00 +/- 0.00
saved checkpoint 1720000
Eval num_timesteps=1720000, episode_reward=-156.94 +/- 92.22
Episode length: 200.00 +/- 0.00
saved checkpoint 1730000
Eval num_timesteps=1730000, episode_reward=-142.28 +/- 80.32
Episode length: 200.00 +/- 0.00
saved checkpoint 1740000
Eval num_timesteps=1740000, episode_reward=-131.05 +/- 76.85
Episode length: 200.00 +/- 0.00
saved checkpoint 1750000
Eval num_timesteps=1750000, episode_reward=-146.92 +/- 96.33
Episode length: 200.00 +/- 0.00
saved checkpoint 1760000
Eval num_timesteps=1760000, episode_reward=-115.85 +/- 88.08
Episode length: 200.00 +/- 0.00
New best mean reward!
saved checkpoint 1770000
Eval num_timesteps=1770000, episode_reward=-134.95 +/- 89.27
Episode length: 200.00 +/- 0.00
saved checkpoint 1780000
Eval num_timesteps=1780000, episode_reward=-164.12 +/- 94.10
Episode length: 200.00 +/- 0.00
saved checkpoint 1790000
Eval num_timesteps=1790000, episode_reward=-171.64 +/- 90.25
Episode length: 200.00 +/- 0.00
saved checkpoint 1800000
Eval num_timesteps=1800000, episode_reward=-139.71 +/- 79.04
Episode length: 200.00 +/- 0.00
saved checkpoint 1810000
Eval num_timesteps=1810000, episode_reward=-150.30 +/- 92.46
Episode length: 200.00 +/- 0.00
saved checkpoint 1820000
Eval num_timesteps=1820000, episode_reward=-158.32 +/- 90.90
Episode length: 200.00 +/- 0.00
saved checkpoint 1830000
Eval num_timesteps=1830000, episode_reward=-143.29 +/- 68.31
Episode length: 200.00 +/- 0.00
saved checkpoint 1840000
Eval num_timesteps=1840000, episode_reward=-153.94 +/- 82.37
Episode length: 200.00 +/- 0.00
saved checkpoint 1850000
Eval num_timesteps=1850000, episode_reward=-155.38 +/- 94.05
Episode length: 200.00 +/- 0.00
saved checkpoint 1860000
Eval num_timesteps=1860000, episode_reward=-173.86 +/- 80.84
Episode length: 200.00 +/- 0.00
saved checkpoint 1870000
Eval num_timesteps=1870000, episode_reward=-142.49 +/- 84.51
Episode length: 200.00 +/- 0.00
saved checkpoint 1880000
Eval num_timesteps=1880000, episode_reward=-133.14 +/- 64.27
Episode length: 200.00 +/- 0.00
saved checkpoint 1890000
Eval num_timesteps=1890000, episode_reward=-142.32 +/- 86.14
Episode length: 200.00 +/- 0.00
saved checkpoint 1900000
Eval num_timesteps=1900000, episode_reward=-135.82 +/- 100.52
Episode length: 200.00 +/- 0.00
saved checkpoint 1910000
Eval num_timesteps=1910000, episode_reward=-162.72 +/- 88.68
Episode length: 200.00 +/- 0.00
saved checkpoint 1920000
Eval num_timesteps=1920000, episode_reward=-147.94 +/- 99.38
Episode length: 200.00 +/- 0.00
saved checkpoint 1930000
Eval num_timesteps=1930000, episode_reward=-135.00 +/- 97.88
Episode length: 200.00 +/- 0.00
saved checkpoint 1940000
Eval num_timesteps=1940000, episode_reward=-143.31 +/- 84.34
Episode length: 200.00 +/- 0.00
saved checkpoint 1950000
Eval num_timesteps=1950000, episode_reward=-141.19 +/- 85.70
Episode length: 200.00 +/- 0.00
saved checkpoint 1960000
Eval num_timesteps=1960000, episode_reward=-160.20 +/- 63.02
Episode length: 200.00 +/- 0.00
saved checkpoint 1970000
Eval num_timesteps=1970000, episode_reward=-138.62 +/- 79.16
Episode length: 200.00 +/- 0.00
saved checkpoint 1980000
Eval num_timesteps=1980000, episode_reward=-146.84 +/- 79.57
Episode length: 200.00 +/- 0.00
saved checkpoint 1990000
Eval num_timesteps=1990000, episode_reward=-147.66 +/- 90.50
Episode length: 200.00 +/- 0.00
saved checkpoint 2000000
Eval num_timesteps=2000000, episode_reward=-143.19 +/- 89.50
Episode length: 200.00 +/- 0.00
saved checkpoint 2010000
Eval num_timesteps=2010000, episode_reward=-147.09 +/- 83.86
Episode length: 200.00 +/- 0.00
saved checkpoint 2020000
Eval num_timesteps=2020000, episode_reward=-148.60 +/- 88.80
Episode length: 200.00 +/- 0.00
saved checkpoint 2030000
Eval num_timesteps=2030000, episode_reward=-147.08 +/- 90.49
Episode length: 200.00 +/- 0.00
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_459
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_461
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_460
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_462
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_463
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_468
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_464
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_467
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_469
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_465
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_470
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_466
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_470
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_471
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_472
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_472
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_473
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_474
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_475
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_475
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_476
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_477
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_477
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_477
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_478
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_478
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_478
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_478
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_478
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_478
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_479
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_480
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_480
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_480
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_481
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_481
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_482
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_483
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_483
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_482
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_484
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_484
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_485
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_484
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_486
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_487
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_487
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_487
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_487
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_490
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_488
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_492
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_489
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_492
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_492
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_492
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_491
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_493
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_490
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_493
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_493
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_494
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_493
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_493
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_494
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_495
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_496
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_497
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_498
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_498
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_498
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_497
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_499
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_500
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_501
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_499
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_504
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_501
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_502
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_503
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_504
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_505
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_503
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_506
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_504
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_507
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_508
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_508
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_509
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_510
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_511
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_510
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_512
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_513
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_514
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_514
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_515
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_516
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_515
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_517
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_518
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_518
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_517
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_519
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_519
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_519
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_520
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_521
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_521
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_522
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_522
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_524
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_523
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_523
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_523
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_524
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_523
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_525
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_525
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_527
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_525
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_526
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_528
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_529
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_529
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_530
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_531
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_530
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_530
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_531
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_532
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_533
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_533
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_534
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_534
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_535
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_536
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_536
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_536
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_537
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_537
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_538
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_539
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_538
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_539
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_539
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_540
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_540
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_538
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_539
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_540
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_539
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_539
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_542
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_543
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_541
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_542
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_542
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_543
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_544
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_544
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_545
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_546
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_547
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_548
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_548
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_548
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_550
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_549
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_550
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_551
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_552
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_551
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_552
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_552
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_553
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_553
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_554
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_556
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_555
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_557
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_557
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_557
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_558
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_558
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_559
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_560
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_561
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_563
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_562
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_562
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_565
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_564
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_565
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_566
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_566
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_567
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_567
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_567
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_568
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_569
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_570
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_570
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_571
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_571
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_571
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_572
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_573
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_573
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_574
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_575
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_576
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_575
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_575
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_575
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_575
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_577
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_575
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_577
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_578
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_578
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_578
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_578
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_578
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_578
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_579
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_579
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_579
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_579
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_582
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_580
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_580
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_581
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_582
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_580
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_583
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_583
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_585
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_585
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_584
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_584
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_586
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_587
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_586
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_587
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_586
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_587
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_587
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_588
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_589
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_589
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_590
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_590
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_591
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_592
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_591
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_592
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_592
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_592
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_592
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_594
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_593
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_594
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_595
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_597
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_596
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_596
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_597
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_597
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_598
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_598
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_598
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_599
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_599
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_600
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_601
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_601
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_601
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_601
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_603
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_602
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_602
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_603
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_604
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_604
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_604
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_605
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_606
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_605
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_607
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_608
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_607
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_609
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_610
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_611
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_610
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_610
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_612
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_613
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_613
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_614
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_614
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_614
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_614
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_615
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_617
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_616
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_618
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_619
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_619
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_620
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_620
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_621
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_621
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_621
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_621
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_621
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_622
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_623
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_623
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_624
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_624
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_626
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_625
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_625
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_628
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_628
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_627
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_629
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_631
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_630
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_631
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_631
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_632
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_632
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_633
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_633
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_634
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_632
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_635
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_635
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_636
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_635
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_637
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_638
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_639
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_640
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_639
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_640
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_640
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_639
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_641
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_641
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_641
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_642
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_642
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_643
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_644
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_644
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_645
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_644
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_645
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_646
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_644
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_647
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_648
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_649
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_648
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_649
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_650
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_651
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_652
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_653
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_655
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_655
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_654
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_656
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_656
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_657
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_658
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_658
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_658
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_658
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_659
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_658
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_660
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_660
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_660
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_661
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_662
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_663
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_663
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_663
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_664
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_664
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_665
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_666
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_665
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_666
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_666
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_666
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_667
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_667
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_668
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_669
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_668
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_668
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_668
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_668
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_669
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_669
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_670
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_671
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_672
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_674
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_673
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_674
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_675
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_676
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_675
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_677
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_678
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_678
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_679
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_680
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_681
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_681
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_681
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_683
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_683
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_682
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_683
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_684
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_683
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_684
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_685
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_686
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_686
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_688
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_687
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_689
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_689
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_691
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_690
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_692
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_693
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_692
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_694
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_695
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_694
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_695
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_695
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_695
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_696
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_696
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_696
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_696
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_697
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_697
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_698
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_699
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_701
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_699
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_700
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_702
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_703
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_704
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_704
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_704
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_704
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_705
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_705
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_705
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_706
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_706
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_708
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_709
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_707
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_710
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_711
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_712
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_712
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_712
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_713
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_714
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_715
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_715
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_717
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_716
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_716
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_719
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_718
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_720
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_721
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_721
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_720
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_720
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_722
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_723
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_722
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_724
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_723
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_726
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_725
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_727
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_727
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_729
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_728
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_729
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_730
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_730
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_731
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_731
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_732
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_732
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_733
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_733
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_733
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_734
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_735
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_735
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_735
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_736
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_735
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_737
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_737
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_737
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_738
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_739
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_740
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_741
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_741
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_741
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_743
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_742
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_745
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_744
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_743
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_744
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_745
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_746
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_747
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_747
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_747
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_748
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_749
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_750
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_750
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_751
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_751
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_752
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_752
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_752
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_754
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_753
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_755
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_754
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_756
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_756
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_757
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_757
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_758
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_759
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_760
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_759
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_760
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_761
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_759
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_762
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_763
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_764
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_764
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_764
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_765
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_766
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_766
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_767
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_767
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_769
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_768
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_769
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_768
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_770
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_771
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_771
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_772
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_773
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_773
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_772
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_772
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_772
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_773
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_773
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_774
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_777
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_775
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_776
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_776
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_776
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_777
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_778
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_778
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_779
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_780
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_779
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_781
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_782
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_783
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_782
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_785
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_785
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_784
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_786
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_786
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_787
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_787
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_787
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_787
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_788
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_789
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_789
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_788
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_790
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_790
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_791
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_792
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_792
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_792
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_793
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_793
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_792
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_794
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_794
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_794
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_796
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_795
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_795
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_795
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_797
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_799
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_798
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_799
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_800
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_801
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_802
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_804
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_803
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_805
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_805
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_806
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_807
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_807
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_807
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_807
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_808
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_809
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_809
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_810
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_811
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_809
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_810
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_813
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_813
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_813
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_812
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_814
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_814
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_816
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_815
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_818
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_817
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_818
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_818
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_819
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_819
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_821
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_820
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_822
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_819
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_821
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_823
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_824
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_824
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_826
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_825
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_825
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_826
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_826
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_827
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_828
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_828
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_829
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_830
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_830
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_830
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_831
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_831
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_831
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_832
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_833
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_832
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_832
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_832
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_834
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_833
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_835
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_835
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_836
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_836
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_837
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_837
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_837
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_838
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_838
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_839
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_839
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_840
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_839
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_841
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_841
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_841
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_842
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_843
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_842
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_843
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_844
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_845
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_844
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_844
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_846
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_846
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_847
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_846
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_848
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_848
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_848
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_848
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_849
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_850
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_851
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_850
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_850
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_850
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_850
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_850
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_852
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_853
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_852
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_854
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_855
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_854
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_855
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_855
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_855
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_856
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_854
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_855
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_857
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_858
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_857
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_858
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_859
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_860
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_861
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_862
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_862
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_864
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_863
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_866
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_865
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_864
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_869
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_867
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_867
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_868
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_867
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_868
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_870
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_871
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_871
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_871
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_872
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_873
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_873
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_873
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_874
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_875
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_876
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_875
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_877
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_878
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_878
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_878
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_879
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_880
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_879
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_879
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_880
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_881
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_883
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_882
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_882
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_885
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_884
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_885
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_885
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_886
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_886
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_886
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_886
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_887
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_887
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_888
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_888
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_889
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_890
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_890
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_891
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_891
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_891
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_891
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_892
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_893
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_894
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_895
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_895
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_895
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_895
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_895
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_896
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_897
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_897
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_898
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_899
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_898
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_901
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_900
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_902
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_901
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_904
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_901
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_901
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_903
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_903
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_905
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_906
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_907
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_907
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_907
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_908
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_908
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_910
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_909
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_909
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_911
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_912
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_912
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_911
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_911
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_913
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_913
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_914
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_914
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_914
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_914
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_915
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_916
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_916
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_918
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_917
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_917
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_918
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_918
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_917
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_919
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_920
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_919
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_920
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_920
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_923
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_921
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_921
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_922
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_923
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_923
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_924
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_926
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_925
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_926
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 4096),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_Pendulum_surface/ppo_sam/Pendulum-v1_925
Number of episodes: 10
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
key_name:episode_rewards
Pendulum
./runs/sam_ppo_Pendulum_Pendulum-v1_ppo_sam_episoderewards_2dcontourf.png
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
{"ALGO": "ppo_sam"}
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cuda
Log path: ./runs/sam_ppo_cartpole_checkpoints/ppo_sam/CartPole-v1_3
saved checkpoint 0010000
Eval num_timesteps=10000, episode_reward=26.04 +/- 13.56
Episode length: 26.04 +/- 13.56
New best mean reward!
saved checkpoint 0020000
Eval num_timesteps=20000, episode_reward=28.20 +/- 14.78
Episode length: 28.20 +/- 14.78
New best mean reward!
saved checkpoint 0030000
Eval num_timesteps=30000, episode_reward=21.96 +/- 11.26
Episode length: 21.96 +/- 11.26
saved checkpoint 0040000
Eval num_timesteps=40000, episode_reward=25.58 +/- 17.39
Episode length: 25.58 +/- 17.39
saved checkpoint 0050000
Eval num_timesteps=50000, episode_reward=26.56 +/- 20.18
Episode length: 26.56 +/- 20.18
saved checkpoint 0060000
Eval num_timesteps=60000, episode_reward=25.28 +/- 15.72
Episode length: 25.28 +/- 15.72
saved checkpoint 0070000
Eval num_timesteps=70000, episode_reward=24.96 +/- 13.15
Episode length: 24.96 +/- 13.15
saved checkpoint 0080000
Eval num_timesteps=80000, episode_reward=21.74 +/- 8.35
Episode length: 21.74 +/- 8.35
saved checkpoint 0090000
Eval num_timesteps=90000, episode_reward=24.84 +/- 10.97
Episode length: 24.84 +/- 10.97
saved checkpoint 0100000
Eval num_timesteps=100000, episode_reward=20.14 +/- 10.36
Episode length: 20.14 +/- 10.36
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_436
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 64
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 63
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 65
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_437
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 65
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_443
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_443
Number of episodes: 66
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_443
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 91
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_444
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_438
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_443
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_439
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_443
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_440
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_443
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_441
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_442
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_445
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_445
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_446
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_446
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_447
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_447
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_447
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_447
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_447
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_448
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_448
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_449
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_450
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_450
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_449
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_449
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_450
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_450
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_450
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_451
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_451
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_452
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_453
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_453
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_453
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_455
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_453
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_455
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_454
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_455
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_458
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_458
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_456
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_460
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_458
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_458
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_461
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_462
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_458
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_459
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_463
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_457
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_460
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_459
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_460
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_465
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_465
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_465
Number of episodes: 62
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_464
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_465
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_465
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_470
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_469
Number of episodes: 66
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_468
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_470
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_466
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_468
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_468
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_467
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_468
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_471
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_470
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_469
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_473
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_474
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_472
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_474
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_476
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_475
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_478
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_477
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_477
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_479
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_480
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_481
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_481
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_482
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_483
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_484
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_485
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_486
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_486
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_486
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_487
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_487
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_488
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_488
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_489
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_489
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_489
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_490
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_489
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_491
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_491
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_491
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_491
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_491
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_493
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_492
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_493
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_492
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_492
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_492
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_493
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_492
Number of episodes: 66
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_493
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_493
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_494
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_494
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_495
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_495
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_496
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_495
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_497
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_496
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_498
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_499
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_499
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_501
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_500
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_499
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_501
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_499
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_499
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_500
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_502
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_501
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_501
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_502
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_501
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_501
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_503
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_503
Number of episodes: 62
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_503
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_503
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_504
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_503
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_505
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_506
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_505
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_503
Number of episodes: 58
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_508
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_507
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_509
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_508
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_507
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_510
Number of episodes: 66
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_512
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_511
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_511
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_511
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_513
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_513
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_514
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_514
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_514
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_515
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_515
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_516
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_516
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_516
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_518
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_517
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_519
Number of episodes: 66
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_520
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_518
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_520
Number of episodes: 65
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_521
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_522
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_522
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_522
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_522
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_523
Number of episodes: 63
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_524
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_524
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_525
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_526
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_527
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_527
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_528
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_527
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_528
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_530
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_529
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_530
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_529
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_531
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_531
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_531
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_532
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_534
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_534
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_534
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_533
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_533
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_533
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_535
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_537
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_536
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_537
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_537
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_536
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_537
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_536
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_537
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_538
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_538
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_538
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_539
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_540
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_541
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_540
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_540
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_541
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_543
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_542
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_542
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_544
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_545
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_546
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_547
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_546
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_547
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_547
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_548
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_549
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_549
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_549
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_549
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_549
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_550
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_551
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_551
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_551
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_552
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_553
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_553
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_553
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_553
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_554
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_555
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_554
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_555
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_556
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_556
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_556
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_557
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_556
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_559
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_560
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_559
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_558
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_560
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_561
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_562
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_562
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_563
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_563
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_564
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_565
Number of episodes: 64
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_565
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_565
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_566
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_565
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_566
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_566
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_567
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_568
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_567
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_567
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_567
Number of episodes: 64
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_569
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_569
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_569
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_570
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_572
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_570
Number of episodes: 91
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_571
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_573
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_575
Number of episodes: 91
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_574
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_575
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_575
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_576
Number of episodes: 67
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_576
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_577
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_576
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_577
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_578
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_580
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_580
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_579
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_581
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_582
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_582
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_584
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_583
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_585
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_585
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_583
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_585
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_585
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_586
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_586
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_587
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_587
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_586
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_589
Number of episodes: 95
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_588
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_588
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_590
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_590
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_591
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_592
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_593
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_593
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_595
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_594
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_595
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_595
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_595
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_596
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_598
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_597
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_599
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_600
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_601
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_601
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_600
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_601
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_603
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_602
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_603
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_603
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_604
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_604
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_605
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_605
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_605
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_606
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_607
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_607
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_607
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_606
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_606
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_606
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_608
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_609
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_609
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_611
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_610
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_610
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_610
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_612
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_613
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_614
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_615
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_614
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_614
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_616
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_616
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_616
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_617
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_618
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_620
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_619
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_621
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_622
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_621
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_622
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_622
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_623
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_622
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_624
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_625
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_625
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_625
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_626
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_627
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_628
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_630
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_629
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_630
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_630
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_630
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_631
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_631
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_631
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_632
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_633
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_634
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_635
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_635
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_634
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_636
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_637
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_637
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_638
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_637
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_638
Number of episodes: 92
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_639
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_640
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_641
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_642
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_642
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_643
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_644
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_642
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_643
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_643
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_643
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_645
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_646
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_646
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_645
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_647
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_647
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_647
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_648
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_648
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_648
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_649
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_650
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_652
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_652
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_651
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_653
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_651
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_654
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_653
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_653
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_655
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_655
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_657
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_656
Number of episodes: 92
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_658
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_660
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_658
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_659
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_659
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_659
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_663
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_661
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_662
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_664
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_664
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_664
Number of episodes: 93
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_666
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_665
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_666
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_667
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_668
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_669
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_671
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_670
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_672
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_673
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_674
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_675
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_675
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_675
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_676
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_678
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_675
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_678
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_677
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_679
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_680
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_680
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_681
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_682
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_683
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_684
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_683
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_683
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_684
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_683
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_685
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_684
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_686
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_686
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_686
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_687
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_687
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_687
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_688
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_688
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_689
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_689
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_689
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_690
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_691
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_692
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_691
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_691
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_692
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_692
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_694
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_693
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_695
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_693
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_693
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_697
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_697
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_696
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_697
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_698
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_697
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_699
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_701
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_700
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_700
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_701
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_702
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_702
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_703
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_703
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_704
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_704
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_705
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_705
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_706
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_706
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_705
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_707
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_707
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_707
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_707
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_707
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_707
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_708
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_709
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_708
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_708
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_710
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_711
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_712
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_713
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_712
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_713
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_712
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_714
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_714
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_714
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_716
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_715
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_715
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_715
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_717
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_718
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_716
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_720
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_719
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_719
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_720
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_721
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_721
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_722
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_721
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_722
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_723
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_724
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_724
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_725
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_724
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_725
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_725
Number of episodes: 69
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_726
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_726
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_726
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_727
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_727
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_728
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_730
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_729
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_731
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_732
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_733
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_732
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_734
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_732
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_735
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_733
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_737
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_736
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_739
Number of episodes: 95
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_738
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_738
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_740
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_741
Number of episodes: 94
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_743
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_742
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_740
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_742
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_743
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_744
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_745
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_745
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_746
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_747
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_748
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_748
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_750
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_750
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_750
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_750
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_749
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_750
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_750
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_752
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_751
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_751
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_752
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_752
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_753
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_755
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_755
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_755
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_754
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_756
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_758
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_757
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_757
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_757
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_758
Number of episodes: 64
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_759
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_760
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_760
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_760
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_761
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_761
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_762
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_761
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_763
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_762
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_764
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_764
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_764
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_764
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_765
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_765
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_766
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_767
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_766
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_768
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_769
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_768
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_769
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_770
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_770
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_771
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_771
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_772
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_772
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_771
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_772
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_771
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_773
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_773
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_774
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_775
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_776
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_777
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_777
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_776
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_776
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_779
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_778
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_779
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_778
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_779
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_779
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_781
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_780
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_780
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_780
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_780
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_781
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_781
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_781
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_782
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_780
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_783
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_784
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_784
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_784
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_787
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_786
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_785
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_788
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_788
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_789
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_789
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_790
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_791
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_791
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_791
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_792
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_792
Number of episodes: 91
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_794
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_793
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_793
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_795
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_795
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_796
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_797
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_797
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_798
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_797
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_800
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_799
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_799
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_799
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_802
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_801
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_801
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_803
Number of episodes: 71
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_803
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_804
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_806
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_804
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_805
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_806
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_805
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_807
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_807
Number of episodes: 68
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_809
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_808
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_809
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_811
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_810
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_812
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_810
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_813
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_813
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_813
Number of episodes: 93
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_814
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_815
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_815
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_816
Number of episodes: 93
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_817
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_817
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_817
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_817
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_817
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_818
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_818
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_819
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_819
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_819
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_820
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_821
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_820
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_821
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_822
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_822
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_823
Number of episodes: 95
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_823
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_824
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_826
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_824
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_826
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_825
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_827
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_827
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_827
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_828
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_828
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_827
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_829
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_830
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_830
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_830
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_831
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_831
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_832
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_832
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_833
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_834
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_834
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_834
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_835
Number of episodes: 72
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_837
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_836
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_837
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_839
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_837
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_838
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_840
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_840
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_841
Number of episodes: 87
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_842
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_842
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_844
Number of episodes: 91
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_843
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_845
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_846
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_848
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_847
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_847
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_848
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_849
Number of episodes: 93
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_849
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_849
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_850
Number of episodes: 93
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_850
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_851
Number of episodes: 94
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_851
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_852
Number of episodes: 73
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_851
Number of episodes: 62
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_851
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_852
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_853
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_853
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_853
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_854
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_854
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_855
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_854
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_856
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_857
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_857
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_858
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_858
Number of episodes: 90
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_859
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_859
Number of episodes: 89
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_863
Number of episodes: 80
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_862
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_861
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_860
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_864
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_864
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_865
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_866
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_867
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_867
Number of episodes: 75
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_868
Number of episodes: 88
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_868
Number of episodes: 92
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_867
Number of episodes: 94
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_868
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_869
Number of episodes: 70
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_870
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_871
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_871
Number of episodes: 79
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_871
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_871
Number of episodes: 76
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_873
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_872
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_873
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_874
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_874
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_874
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_873
Number of episodes: 81
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_874
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_875
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_874
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_875
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_877
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_875
Number of episodes: 77
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_876
Number of episodes: 82
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_876
Number of episodes: 78
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_875
Number of episodes: 86
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_878
Number of episodes: 91
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_879
Number of episodes: 74
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_879
Number of episodes: 84
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_881
Number of episodes: 85
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_880
Number of episodes: 92
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 256),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam, adaptive=True))')])
Using 8 environments
cpu
Log path: runs/sam_ppo_cartpole_surface/ppo_sam/CartPole-v1_882
Number of episodes: 83
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
key_name:episode_rewards
CartPole
./runs/sam_ppo_cartpole_CartPole-v1_ppo_sam_episoderewards_2dcontourf.png
