/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_15
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_13
evaluating  0190000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_11
evaluating  0230000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_10
evaluating  0250000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_14
evaluating  0120000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0180000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_11
evaluating  0280000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_13
evaluating  0260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_13
evaluating  0240000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_11
evaluating  0270000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0200000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_12
evaluating  0170000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_13
evaluating  0160000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0210000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0290000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0020000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_11
evaluating  0140000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_13
evaluating  0220000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_14
evaluating  0300000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_12
evaluating  0110000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0060000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0150000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_10
evaluating  0080000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0100000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0030000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_16
evaluating  0050000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_12
evaluating  0090000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('buffer_size', 200000),
             ('gamma', 0.98),
             ('gradient_steps', -1),
             ('learning_rate', 0.001),
             ('learning_starts', 10000),
             ('n_timesteps', 300000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(net_arch=[400, 300], optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('train_freq', [1, 'episode'])])
Using 1 environments
Applying normal noise with std 0.1
cuda
Log path: runs/eval_grad/ddpg_sam_LunarLanderContinuous/ddpg_sam/LunarLanderContinuous-v2_12
evaluating  0040000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Selecting 33 checkpoints out of 201
['0010000', '0070000', '0130000', '0200000', '0260000', '0320000', '0390000', '0450000', '0510000', '0570000', '0630000', '0700000', '0760000', '0820000', '0890000', '0950000', '1010000', '1070000', '1130000', '1200000', '1260000', '1320000', '1390000', '1450000', '1510000', '1570000', '1630000', '1700000', '1760000', '1820000', '1890000', '1950000', '2010000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  1700000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  1070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  0450000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  0820000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  1320000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  1820000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  0260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  0570000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  0130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  0320000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_1
evaluating  0950000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0390000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_4
evaluating  0890000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  1950000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0510000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  1570000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  2010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  1200000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_4
evaluating  1630000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  1130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0760000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_4
evaluating  1760000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_4
evaluating  1010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  1450000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0700000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  1510000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0630000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_3
evaluating  0200000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_4
evaluating  1390000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_2
evaluating  1260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_Pendulum/ppo/Pendulum-v1_4
evaluating  1890000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
['0010000', '0020000', '0030000', '0040000', '0050000', '0060000', '0070000', '0080000', '0090000', '0100000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0020000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0030000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0060000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0040000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0100000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0090000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0050000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy')])
Using 8 environments
cuda
Log path: runs/eval_grad/ppo_cartpole/ppo/CartPole-v1_1
evaluating  0080000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
['0010000', '0020000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 0.1),
             ('ent_coef', 0.00429),
             ('gae_lambda', 0.9),
             ('gamma', 0.9999),
             ('learning_rate', 7.77e-05),
             ('max_grad_norm', 5),
             ('n_envs', 1),
             ('n_epochs', 10),
             ('n_steps', 8),
             ('n_timesteps', 20000.0),
             ('normalize', True),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(log_std_init=-3.29, ortho_init=False)'),
             ('use_sde', True),
             ('vf_coef', 0.19)])
Using 1 environments
Normalization activated: {'gamma': 0.9999}
cuda
Log path: runs/eval_grad/ppo_MountainCarContinuous/ppo/MountainCarContinuous-v0_1
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
evaluating  0010000
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 0.1),
             ('ent_coef', 0.00429),
             ('gae_lambda', 0.9),
             ('gamma', 0.9999),
             ('learning_rate', 7.77e-05),
             ('max_grad_norm', 5),
             ('n_envs', 1),
             ('n_epochs', 10),
             ('n_steps', 8),
             ('n_timesteps', 20000.0),
             ('normalize', True),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(log_std_init=-3.29, ortho_init=False)'),
             ('use_sde', True),
             ('vf_coef', 0.19)])
Using 1 environments
Normalization activated: {'gamma': 0.9999}
cuda
Log path: runs/eval_grad/ppo_MountainCarContinuous/ppo/MountainCarContinuous-v0_1
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
evaluating  0020000
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Selecting 33 checkpoints out of 101
['0010000', '0040000', '0070000', '0100000', '0130000', '0170000', '0200000', '0230000', '0260000', '0290000', '0320000', '0350000', '0390000', '0420000', '0450000', '0480000', '0510000', '0540000', '0570000', '0600000', '0630000', '0670000', '0700000', '0730000', '0760000', '0790000', '0820000', '0850000', '0890000', '0920000', '0950000', '0980000', '1010000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0040000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0100000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0170000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0230000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0200000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0350000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0290000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0420000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0320000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0390000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0450000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0670000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0570000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0630000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  1010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0600000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0510000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0920000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0480000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0890000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_3
evaluating  0950000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0730000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0700000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_1
evaluating  0850000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0760000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_3
evaluating  0540000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0980000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0820000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy')])
Using 16 environments
cuda
Log path: runs/eval_grad/ppo_LunarLanderContinuous/ppo/LunarLanderContinuous-v2_2
evaluating  0790000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Selecting 33 checkpoints out of 201
['0010000', '0070000', '0130000', '0200000', '0260000', '0320000', '0390000', '0450000', '0510000', '0570000', '0630000', '0700000', '0760000', '0820000', '0890000', '0950000', '1010000', '1070000', '1130000', '1200000', '1260000', '1320000', '1390000', '1450000', '1510000', '1570000', '1630000', '1700000', '1760000', '1820000', '1890000', '1950000', '2010000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  1760000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_1
evaluating  0200000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_1
evaluating  0570000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_1
evaluating  1010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_1
evaluating  0130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_1
evaluating  0950000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  1070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0630000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  1450000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0760000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  1130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0820000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0390000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  0890000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  0510000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  0260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1890000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  1820000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  0450000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  2010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1700000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1200000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1950000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  0700000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1510000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  1390000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  1630000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_4
evaluating  1320000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_2
evaluating  1570000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('clip_range', 0.2),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.95),
             ('gamma', 0.99),
             ('learning_rate', 0.0003),
             ('n_envs', 8),
             ('n_epochs', 10),
             ('n_steps', 2048),
             ('n_timesteps', 2000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_Pendulum/ppo_sam/Pendulum-v1_3
evaluating  0320000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
['0010000', '0020000', '0030000', '0040000', '0050000', '0060000', '0070000', '0080000', '0090000', '0100000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_1
evaluating  0030000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0100000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_1
evaluating  0050000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0080000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_3
evaluating  0070000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0040000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0090000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0060000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 'lin_0.2'),
             ('ent_coef', 0.0),
             ('gae_lambda', 0.8),
             ('gamma', 0.98),
             ('learning_rate', 'lin_0.001'),
             ('n_envs', 8),
             ('n_epochs', 20),
             ('n_steps', 32),
             ('n_timesteps', 100000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 8 environments
cuda
Log path: runs/eval_grad/sam_ppo_cartpole/ppo_sam/CartPole-v1_2
evaluating  0020000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
['0010000', '0020000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 0.1),
             ('ent_coef', 0.00429),
             ('gae_lambda', 0.9),
             ('gamma', 0.9999),
             ('learning_rate', 7.77e-05),
             ('max_grad_norm', 5),
             ('n_envs', 1),
             ('n_epochs', 10),
             ('n_steps', 8),
             ('n_timesteps', 20000.0),
             ('normalize', True),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(log_std_init=-3.29, ortho_init=False, optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('use_sde', True),
             ('vf_coef', 0.19)])
Using 1 environments
Normalization activated: {'gamma': 0.9999}
cuda
Log path: runs/eval_grad/sam_ppo_MountainCarContinuous/ppo_sam/MountainCarContinuous-v0_1
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
evaluating  0010000
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 256),
             ('clip_range', 0.1),
             ('ent_coef', 0.00429),
             ('gae_lambda', 0.9),
             ('gamma', 0.9999),
             ('learning_rate', 7.77e-05),
             ('max_grad_norm', 5),
             ('n_envs', 1),
             ('n_epochs', 10),
             ('n_steps', 8),
             ('n_timesteps', 20000.0),
             ('normalize', True),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(log_std_init=-3.29, ortho_init=False, optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))'),
             ('use_sde', True),
             ('vf_coef', 0.19)])
Using 1 environments
Normalization activated: {'gamma': 0.9999}
cuda
Log path: runs/eval_grad/sam_ppo_MountainCarContinuous/ppo_sam/MountainCarContinuous-v0_1
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
evaluating  0020000
Normalization activated: {'gamma': 0.9999, 'norm_reward': False}
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Selecting 33 checkpoints out of 58
['0010000', '0030000', '0050000', '0060000', '0080000', '0100000', '0120000', '0130000', '0150000', '0170000', '0190000', '0210000', '0220000', '0240000', '0260000', '0280000', '0290000', '0310000', '0330000', '0350000', '0370000', '0380000', '0400000', '0420000', '0440000', '0460000', '0470000', '0490000', '0510000', '0530000', '0540000', '0560000', '0580000']
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0010000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0030000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0060000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0050000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0080000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0100000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0120000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0130000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0150000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0170000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0190000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0210000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0220000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0240000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0490000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0440000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0260000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0460000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0470000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0290000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0310000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0280000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0560000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0530000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0420000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0350000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0510000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0540000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0400000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_1
evaluating  0380000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0370000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_3
evaluating  0330000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('ent_coef', 0.01),
             ('gae_lambda', 0.98),
             ('gamma', 0.999),
             ('n_envs', 16),
             ('n_epochs', 4),
             ('n_steps', 1024),
             ('n_timesteps', 1000000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs',
              'dict(optimizer_class=SAM, '
              'optimizer_kwargs=dict(base_optimizer=Adam))')])
Using 16 environments
cuda
Log path: runs/eval_grad/sam_ppo_LunarLanderContinuous/ppo_sam/LunarLanderContinuous-v2_2
evaluating  0580000
Number of episodes: 200
dumping results
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
/data/yfs5313/conda/envs/rl_final/lib/python3.9/site-packages/stable_baselines3/__init__.py
